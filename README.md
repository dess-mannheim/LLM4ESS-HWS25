# IS 617 Large Language Models for the Economic and Social Sciences - HWS25 (University of Mannheim)
A course developed and taught by Indira Sen, Abigail Hayes, and Georg Ahnert

This course aims to equip students with the theoretical foundations and practical skills necessary to leverage Large Language Models (LLMs) in computational social science research. Students will explore how LLMs can be used for analyzing social and economic data, modeling human behavior, and generating insights from large-scale data sources. They will also learn about the challenges of using LLMs for social research and how social science principles can help audit and evaluate LLMs.

# Topics and Readings

**Week 1: Course Introduction & Demystifying LLMs 1: Tokens, Text Representation and Classification**

[How to read a paper](https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf)

[Can Generative AI improve social science?](https://www.pnas.org/doi/10.1073/pnas.2314021121)

**Week 2: Demystifying LLMs 2: Word Embeddings and Transformers**

[Word Embeddings](https://lena-voita.github.io/nlp_course/word_embeddings.html)
[Introduction to Transformers](https://www.youtube.com/watch?v=XfpMkf4rD6E)

**Week 3: Demystifying LLMs 3: Generative LLMs**

[Language Modeling](https://lena-voita.github.io/nlp_course/language_modeling.html)
[Embers of autoregression show how large language models are shaped by the problem they are trained to solve.](https://www.pnas.org/doi/10.1073/pnas.2322420121)

**Week 4: Interacting with and Steering LLMs: Prompting, Fine-tuning**

[The prompt report: a systematic survey of prompt engineering techniques.](https://arxiv.org/abs/2406.06608)
[Fine-tuning](https://developers.google.com/machine-learning/glossary#fine-tuning)

**Week 5: Infrastructure powering LLMs**

[Illustrating Reinforcement Learning from Human Feedback (RLHF)](https://huggingface.co/blog/rlhf)
[Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research.](https://arxiv.org/abs/2402.00159)

**Week 6: Content Analysis**

	- ChatGPT outperforms crowd workers for text-annotation tasks
	- Chatbots Are Not Reliable Text Annotators

**Week 7: AI-augmented Surveys**

	- Out of one, many: Using language models to simulate human samples
	- Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies

**Week 8: Social Media Simulations**

	- Social Simulacra: Creating Populated Prototypes for Social Computing Systems
	- Simulating social media using large language models to evaluate alternative news feed algorithms

**Week 9: Midway Project Presentations**

**Week 10: Machine Behavior**

	- Rahwan, I., Cebrian, M., Obradovich, N. et al. Machine behaviour. Nature 568, 477–486 (2019). https://doi.org/10.1038/s41586-019-1138-y
	- AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories

**Week 11: Ethical Impacts**

	-  On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?

**Week 12: AI Safety and Alignment**

	- US eating disorder helpline takes down AI chatbot over harmful advice
	- The PRISM alignment dataset: What participatory, representative and individualised human feedback reveals about the subjective and multicultural alignment of large language models.

**Week 13: Auditing LLMs**

	- Raji, Inioluwa Deborah, et al. "Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing." Proceedings of the 2020 conference on fairness, accountability, and transparency. 2020.
	- Mökander, Jakob, et al. "Auditing large language models: a three-layered approach." AI and Ethics 4.4 (2024): 1085-1115.

**Week 14: Summary and Outlook**

# Credits

This course is based on a course Indira co-taught and co-created with David Garcia at the University of Konstanz. We're also grateful to the following related courses and resources for informing the materials in this one:
  
